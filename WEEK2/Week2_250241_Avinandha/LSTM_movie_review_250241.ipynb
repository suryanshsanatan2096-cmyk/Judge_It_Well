{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AN LSTM MODEL TO DO SENTIMENT ANALYSIS ON MOVIE REVIEW**"
      ],
      "metadata": {
        "id": "KMQ2xBfNFztI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries and preprocessing the dataset"
      ],
      "metadata": {
        "id": "Nmu9mH7jFaVy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Ge6xjlHFnFw-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# reading the csv file using pandas\n",
        "df = pd.read_csv('Test.csv')\n",
        "texts = df[\"text\"].astype(str)\n",
        "labels = df[\"label\"].astype(int)\n",
        "\n",
        "\n",
        "# Basic cleaning function\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<br\\s*/?>\", \" \", text)     # remove HTML breaks\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)  # remove URLs\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)    # remove punctuation\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()       # normalize spaces\n",
        "    return text\n",
        "\n",
        "texts_clean = [clean_text(t) for t in texts]\n",
        "\n",
        "#building voacbulary\n",
        "vocab_size = 20000\n",
        "oov_token = \"<OOV>\"\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(texts_clean)\n",
        "\n",
        "#text -> integers\n",
        "sequences = tokenizer.texts_to_sequences(texts_clean)\n",
        "\n",
        "# truncate sequences\n",
        "max_len = 200\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
        "y = np.array(labels, dtype=\"int32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting the dataset for training(about 70%, used for training)"
      ],
      "metadata": {
        "id": "aI3OqBst-6Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Val shape:  \", X_val.shape, y_val.shape)\n",
        "print(\"Test shape: \", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96S8jT8z-y_8",
        "outputId": "10a12bca-11c6-4d46-f073-3ff339587aa4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (3500, 200) (3500,)\n",
            "Val shape:   (750, 200) (750,)\n",
            "Test shape:  (750, 200) (750,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the dataset"
      ],
      "metadata": {
        "id": "ileNrUc-_QAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = min(vocab_size, len(tokenizer.word_index) + 1)\n",
        "embed_dim = 128\n",
        "lstm_units = 128\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=max_len),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2)),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")  # binary sentiment\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs= 25,\n",
        "    validation_data=(X_val, y_val)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_-V2GnE0Ymf",
        "outputId": "3c9be0a8-d6f8-4b17-b522-589a9bc85b54"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 809ms/step - accuracy: 0.5123 - loss: 0.6921 - val_accuracy: 0.7200 - val_loss: 0.5876\n",
            "Epoch 2/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 920ms/step - accuracy: 0.7662 - loss: 0.5142 - val_accuracy: 0.7587 - val_loss: 0.5530\n",
            "Epoch 3/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 799ms/step - accuracy: 0.9053 - loss: 0.2593 - val_accuracy: 0.7267 - val_loss: 0.6447\n",
            "Epoch 4/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 798ms/step - accuracy: 0.9497 - loss: 0.1351 - val_accuracy: 0.7533 - val_loss: 0.7309\n",
            "Epoch 5/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 823ms/step - accuracy: 0.9731 - loss: 0.0785 - val_accuracy: 0.7613 - val_loss: 0.8523\n",
            "Epoch 6/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 798ms/step - accuracy: 0.9884 - loss: 0.0362 - val_accuracy: 0.7293 - val_loss: 1.0358\n",
            "Epoch 7/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 786ms/step - accuracy: 0.9829 - loss: 0.0536 - val_accuracy: 0.7520 - val_loss: 1.0042\n",
            "Epoch 8/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 807ms/step - accuracy: 0.9971 - loss: 0.0160 - val_accuracy: 0.7347 - val_loss: 1.0907\n",
            "Epoch 9/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 785ms/step - accuracy: 0.9954 - loss: 0.0159 - val_accuracy: 0.7653 - val_loss: 1.3017\n",
            "Epoch 10/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 789ms/step - accuracy: 0.9957 - loss: 0.0130 - val_accuracy: 0.7360 - val_loss: 1.3005\n",
            "Epoch 11/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 815ms/step - accuracy: 0.9969 - loss: 0.0085 - val_accuracy: 0.7213 - val_loss: 1.3379\n",
            "Epoch 12/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 804ms/step - accuracy: 0.9958 - loss: 0.0139 - val_accuracy: 0.7133 - val_loss: 1.4545\n",
            "Epoch 13/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 820ms/step - accuracy: 0.9931 - loss: 0.0172 - val_accuracy: 0.7373 - val_loss: 1.3454\n",
            "Epoch 14/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 791ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.7520 - val_loss: 1.5311\n",
            "Epoch 15/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 767ms/step - accuracy: 0.9885 - loss: 0.0310 - val_accuracy: 0.7267 - val_loss: 1.1422\n",
            "Epoch 16/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 777ms/step - accuracy: 0.9958 - loss: 0.0243 - val_accuracy: 0.7520 - val_loss: 1.1800\n",
            "Epoch 17/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 781ms/step - accuracy: 0.9967 - loss: 0.0107 - val_accuracy: 0.6920 - val_loss: 1.3744\n",
            "Epoch 18/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 802ms/step - accuracy: 0.9946 - loss: 0.0167 - val_accuracy: 0.7827 - val_loss: 1.5421\n",
            "Epoch 19/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 799ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.7533 - val_loss: 1.4115\n",
            "Epoch 20/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 782ms/step - accuracy: 0.9978 - loss: 0.0083 - val_accuracy: 0.7333 - val_loss: 1.6972\n",
            "Epoch 21/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 771ms/step - accuracy: 0.9980 - loss: 0.0050 - val_accuracy: 0.7320 - val_loss: 1.6508\n",
            "Epoch 22/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 774ms/step - accuracy: 0.9999 - loss: 6.0513e-04 - val_accuracy: 0.7280 - val_loss: 1.6890\n",
            "Epoch 23/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 778ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7280 - val_loss: 1.6230\n",
            "Epoch 24/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 790ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7320 - val_loss: 1.7435\n",
            "Epoch 25/25\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 803ms/step - accuracy: 0.9987 - loss: 0.0057 - val_accuracy: 0.7360 - val_loss: 1.4689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalutating the model using test data"
      ],
      "metadata": {
        "id": "kJ21tuhg_Uh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Evaluate on test set\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {acc:.4f}\")\n",
        "\n",
        "#predict sentiment for test data\n",
        "iter =  10\n",
        "count = 0\n",
        "for i in range(iter):\n",
        "    x = X_test[i:i+1]\n",
        "    true_label = y_test[i]\n",
        "\n",
        "    prob = float(model.predict(x, verbose=0)[0][0])\n",
        "    pred_label = 1 if prob >= 0.5 else 0\n",
        "    if pred_label == true_label:\n",
        "      count += 1\n",
        "\n",
        "    print(f\"True label: {true_label}  Pred prob (positive): {prob:.4f}\")\n",
        "    print(\"Predicted:\", \"POSITIVE\" if pred_label == 1 else \"NEGATIVE\")\n",
        "    print(\"\")\n",
        "\n",
        "print(f\"Accuracy = {(100*count/iter) :.4f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0dc0eAlwc62",
        "outputId": "0c738fdd-b10f-4d3f-cbe9-e9a09a2618bc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.6173, Test accuracy: 0.7067\n",
            "True label: 1  Pred prob (positive): 0.9927\n",
            "Predicted: POSITIVE\n",
            "\n",
            "True label: 0  Pred prob (positive): 0.0001\n",
            "Predicted: NEGATIVE\n",
            "\n",
            "True label: 1  Pred prob (positive): 0.0048\n",
            "Predicted: NEGATIVE\n",
            "\n",
            "True label: 0  Pred prob (positive): 0.9987\n",
            "Predicted: POSITIVE\n",
            "\n",
            "True label: 0  Pred prob (positive): 0.0000\n",
            "Predicted: NEGATIVE\n",
            "\n",
            "True label: 1  Pred prob (positive): 0.9994\n",
            "Predicted: POSITIVE\n",
            "\n",
            "True label: 0  Pred prob (positive): 0.1782\n",
            "Predicted: NEGATIVE\n",
            "\n",
            "True label: 0  Pred prob (positive): 0.9984\n",
            "Predicted: POSITIVE\n",
            "\n",
            "True label: 0  Pred prob (positive): 0.0000\n",
            "Predicted: NEGATIVE\n",
            "\n",
            "True label: 0  Pred prob (positive): 0.0001\n",
            "Predicted: NEGATIVE\n",
            "\n",
            "Accuracy = 70.0000 %\n"
          ]
        }
      ]
    }
  ]
}